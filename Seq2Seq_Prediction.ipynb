{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FeqJjZLCF6Mq"
   },
   "source": [
    "# Load Models and Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "PPmR-FQLF6Mu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tejks\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mi9T2TGUF6My"
   },
   "source": [
    "Encoder and decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bM6-wkVVF6M0"
   },
   "outputs": [],
   "source": [
    "encoder_model = load_model('seq2seq_encoder_eng_hin.hd5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jIylUuloF6ND"
   },
   "outputs": [],
   "source": [
    "decoder_model = load_model('seq2seq_decoder_eng_hin.hd5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kubn79plF6NJ"
   },
   "source": [
    "Load tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "H1UHFWqNF6NK"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YOWKb1JJF6NO"
   },
   "outputs": [],
   "source": [
    "encoder_t = pickle.load(open('encoder_tokenizer_eng','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ToC1d4TWF6NR"
   },
   "outputs": [],
   "source": [
    "decoder_t = pickle.load(open('decoder_tokenizer_hin','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TaRz7n4TF6NU"
   },
   "source": [
    "Define Configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QAttBQC9F6NV"
   },
   "outputs": [],
   "source": [
    "max_encoder_seq_length = 22 #From the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nn4lS_ImF6NY"
   },
   "outputs": [],
   "source": [
    "max_decoder_seq_length = 27 #From the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Ssa5U0LCF6Ni"
   },
   "outputs": [],
   "source": [
    "#Dictionary to convert Decoder output into Hindi Words \n",
    "int_to_word_decoder = dict((i,c) for c, i in decoder_t.word_index.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C1eTrSSSF6Nn"
   },
   "source": [
    "# Function to generate Padded sequences for Input string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sd8j8Fd3F6Np"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jnwt21jOF6Nr"
   },
   "outputs": [],
   "source": [
    "def encode_input(input_str):\n",
    "    \n",
    "    #Convert words to indexes\n",
    "    encoder_seq = encoder_t.texts_to_sequences([input_str])\n",
    "    \n",
    "    #Pad sequences\n",
    "    encoder_input_data = pad_sequences(encoder_seq, maxlen=max_encoder_seq_length, padding='post')\n",
    "    \n",
    "    return encoder_input_data    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0CN3nhb9F6Nu"
   },
   "source": [
    "# Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "R5kGrrvKF6Nx"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xb1FKAtjF6N2"
   },
   "outputs": [],
   "source": [
    "def decode_sentence(input_str):\n",
    "    \n",
    "    #Convert input string to padded sequence\n",
    "    input_seq = encode_input(input_str)\n",
    "    \n",
    "    #Get the encoder state values\n",
    "    decoder_initial_states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    #Build a sequence with '<start>' - starting sequence for Decoder\n",
    "    target_seq = np.zeros((1,1))    \n",
    "    target_seq[0][0] = decoder_t.word_index['<start>']\n",
    "    \n",
    "    #flag to check if prediction should be stopped\n",
    "    stop_loop = False\n",
    "    \n",
    "    #Initialize predicted sentence\n",
    "    predicted_sentence = ''\n",
    "    \n",
    "    #start the loop\n",
    "    while not stop_loop:\n",
    "        \n",
    "        predicted_outputs, h, c = decoder_model.predict([target_seq] + \n",
    "                                                        decoder_initial_states_value)\n",
    "        \n",
    "        #Get the predicted output with highest probability\n",
    "        predicted_output = np.argmax(predicted_outputs[0,-1,:])\n",
    "        \n",
    "        #Get the predicted word from predicter integer\n",
    "        predicted_word = int_to_word_decoder[predicted_output]\n",
    "        \n",
    "        #Check if prediction should stop\n",
    "        if(predicted_word == '<end>' or len(predicted_sentence) > max_decoder_seq_length):\n",
    "            \n",
    "            stop_loop = True\n",
    "            continue\n",
    "                    \n",
    "        #Updated predicted sentence\n",
    "        if (len(predicted_sentence) == 0):\n",
    "            predicted_sentence = predicted_word\n",
    "        else:\n",
    "            predicted_sentence = predicted_sentence + ' ' + predicted_word\n",
    "            \n",
    "        #Update target_seq to be the predicted word index\n",
    "        target_seq[0][0] = predicted_output\n",
    "        \n",
    "        #Update initial states value for decoder\n",
    "        decoder_initial_states_value = [h,c]\n",
    "        \n",
    "    \n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fThdfk2uF6N5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "आप कैसे हैं\n"
     ]
    }
   ],
   "source": [
    "if __name__== '__main__':\n",
    "    print(decode_sentence('How are you?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "3d. Seq2Seq_Prediction.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
